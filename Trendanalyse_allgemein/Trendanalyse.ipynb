{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119b614-b3a8-4e1d-b874-266cd8f51b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# install module to read xlsx files\n",
    "!pip install ipyfilechooser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731a73d-4212-403a-b566-18d92d62c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add file-chooser to open file\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "# Create and display a FileChooser widget\n",
    "fc = FileChooser('./data-files')\n",
    "fc.filter_pattern = [ '*.xls', '*.xlsx' ]\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee3278-133b-4f7b-b4ee-500671536292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file and insert column with index\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "  \n",
    "# save file basename without extension in variable to store results with this name\n",
    "path_name, extension= os.path.splitext(fc.selected)\n",
    "file_name= path_name.split('/')\n",
    "data_file_name= file_name[-1]\n",
    "\n",
    "\n",
    "# read selected Excel file\n",
    "print('reading file: ' + fc.selected + '\\n')\n",
    "# Excel Sheet Name is 'Data'\n",
    "df= pd.read_excel(fc.selected, 'Data')\n",
    "#df= pd.read_excel('', 'Tabelle1', parse_dates= ['Ueberschrift1'])\n",
    "#df.rename(columns= { 'Unnamed: 0': 'Date' }, inplace= True)\n",
    "# drop 2nd row\n",
    "#df= df.drop([0])\n",
    "# set index to 'Date' column\n",
    "#df= df.set_index('Date')\n",
    "\n",
    "# insert column with a simple count index for fitting\n",
    "#df.insert(0, 'Range', range(0, len(df)))\n",
    "\n",
    "df.info()\n",
    "print('\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04dd00-141b-4d66-92c8-68b3e51cc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# install module to group checkboxes in a panel\n",
    "!pip install panel==0.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d2350-3611-44a2-a36f-30ce401c9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display checkboxes to select coulumns to delete\n",
    "\n",
    "import panel as pn\n",
    "# activate gui extensions in notebook\n",
    "pn.extension()\n",
    "\n",
    "\n",
    "# create button to toggle all checkboxes at once\n",
    "toggle_all_delete= pn.widgets.Toggle(name='select all')\n",
    "display(toggle_all_delete)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# create a checkbox for each data column\n",
    "column_delete_group= pn.widgets.CheckBoxGroup(\n",
    "    name='column_xdelete_group', value= [], options= list(df.columns),\n",
    "    inline= False)\n",
    "\n",
    "# function is called if button changes\n",
    "def select_all_delete_fn(onoff):\n",
    "    if onoff.new == True:\n",
    "        column_delete_group.value= column_delete_group.options\n",
    "    else:\n",
    "        column_delete_group.value= []\n",
    "\n",
    "# watch state changes of button\n",
    "toggle_all_delete.param.watch(select_all_delete_fn, 'value')\n",
    "\n",
    "print('Select fields to DELETE from list below:\\n')\n",
    "column_delete_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026480e-2e23-4f95-8b0e-7ef9b704832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(column_delete_group.value) > 0:\n",
    "    print('Deleting following fields:\\n')\n",
    "    for column in column_delete_group.value:\n",
    "        print(column)\n",
    "        df= df.drop(column, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247b08a-6802-4611-8e01-a3288d68a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display checkboxes to select columns to analyze\n",
    "\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "# create button to toggle all checkboxes at once\n",
    "toggle_all_analyze= pn.widgets.Toggle(name='select all')\n",
    "display(toggle_all_analyze)\n",
    "print('\\n')\n",
    "\n",
    "column_checkbox_group= pn.widgets.CheckBoxGroup(\n",
    "    name='column_analyze_group', value= [], options= list(df.columns),\n",
    "    inline= False)\n",
    "\n",
    "def select_all_analyze_fn(onoff):\n",
    "    if onoff.new == True:\n",
    "        column_checkbox_group.value= column_checkbox_group.options\n",
    "    else:\n",
    "        column_checkbox_group.value= []\n",
    "\n",
    "toggle_all_analyze.param.watch(select_all_analyze_fn, 'value')\n",
    "\n",
    "print('Select fields to analyze from list below:\\n')\n",
    "column_checkbox_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4666321-6535-4aa5-a00f-d1653e6a718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(column_checkbox_group.value) == 0:\n",
    "    print('Go back and select at least one field to analyze!')\n",
    "else:\n",
    "    print('Selected fields to analyze:\\n')\n",
    "    for value in column_checkbox_group.value:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2fe186-e4f0-4d09-bc9e-44c6279e57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display checkboxes to select date column\n",
    "\n",
    "import panel as pn\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "field_options= list(df.columns)\n",
    "field_options.insert(0, df.index.name)\n",
    "\n",
    "column_date_group= pn.widgets.RadioBoxGroup(\n",
    "    name='column_date_group', value= [], options= list(field_options),\n",
    "    inline= False)\n",
    "\n",
    "print('Select Date field from list below:\\n')\n",
    "column_date_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b4894-c3c2-4047-a598-b558b51b64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_format_options= list(['YYYY (%Y)', 'mmYYYY (%m%Y)', 'mm.YYYY (%m.%Y)', 'mm-YYYY (%m-%Y)', 'mm/YYYY (%m/%Y)', 'YYYYmm (%Y%m)', 'YYYY.mm (%Y.%m)', 'YYYY-mm (%Y-%m)', 'YYYY/mm (%Y/%m)', 'ddmmYYYY (%d%m%Y)', 'dd.mm.YYYY (%d.%m.%Y)', 'dd-mm-YYYY (%d-%m-%Y)', 'dd/mm/YYYY (%d/%m/%Y)', 'mmddYYYY (%m%d%Y)', 'mm.dd.YYYY (%m.%d.%Y)', 'mm-dd-YYYY (%m-%d-%Y)', 'mm/dd/YYYY (%m/%d/%Y)', 'YYYYmmdd (%Y%m%d)', 'YYYY.mm.dd (%Y.%m.%d)', 'YYYY-mm-dd (%Y-%m-%d)', 'YYYY/mm/dd (%Y/%m/%d)', 'YYYYddmm (%Y%d%m)', 'YYYY.dd.mm (%Y.%d.%m)', 'YYYY-dd-mm (%Y-%d-%m)', 'YYYY/dd/mm (%Y/%d/%m)'])\n",
    "\n",
    "date_format_group= pn.widgets.RadioBoxGroup(\n",
    "    name='date_format_group', value= [], options= list(date_format_options),\n",
    "    inline= False)\n",
    "\n",
    "print('Select date format from list below:\\n')\n",
    "date_format_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa9dc7-f7a8-45a9-afd0-7f520beb5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if column_date_group.value:\n",
    "    date_format= date_format_group.value.split('(')[1].split(')')[0]\n",
    "    print('Selected date field:')\n",
    "    print(column_date_group.value, '  format: ' + date_format + '\\n')\n",
    "\n",
    "    if column_date_group.value in df:\n",
    "        if df[column_date_group.value].dtypes != 'datetime64[ns]':\n",
    "            print('column is not of type datetime64[ns], trying to convert...')\n",
    "            df[column_date_group.value]= pd.to_datetime(df[column_date_group.value], format= date_format)\n",
    "\n",
    "        df.set_index(column_date_group.value, inplace = True)\n",
    "        #df= df.assign(datetime_diff=pd.to_datetime(df[column_date_group.value]).diff())\n",
    "\n",
    "df.info()\n",
    "print('\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b2f23-44a8-4a04-bf2e-1f6664ccbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a year column to group by\n",
    "df['year'] = df.index.to_series().dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca860b-55b1-46d8-b6fe-c9e9252b9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display checkboxes to select groupby coulumn\n",
    "\n",
    "import panel as pn\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "groupby_field_options= list(df.columns)\n",
    "groupby_field_options.insert(0, df.index.name)\n",
    "\n",
    "groupby_checkbox_group= pn.widgets.CheckBoxGroup(\n",
    "    name='groupby_checkbox_group', value= [], options= list(groupby_field_options),\n",
    "    inline= False)\n",
    "\n",
    "print('Select fields to group data from below:\\n')\n",
    "groupby_checkbox_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba9155-0c57-40d4-8919-72533cb0bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mean and standard deviation of grouped data to Excel file\n",
    "\n",
    "if len(groupby_checkbox_group.value) > 0:\n",
    "    df_grouped= df.reset_index().groupby(by= groupby_checkbox_group.value)\n",
    "else:\n",
    "    df_grouped= df\n",
    "\n",
    "import os\n",
    "os.makedirs('plots', exist_ok= True)\n",
    "out_file= 'plots/' + data_file_name + '_stats.xlsx'\n",
    "with pd.ExcelWriter(out_file) as writer:\n",
    "    df_grouped.mean().to_excel(writer, sheet_name= 'mean')\n",
    "    df_grouped.std().to_excel(writer, sheet_name= 'std')\n",
    "    \n",
    "print('Datei gespeichert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c2e20-c0d3-4744-91a0-784f99e2d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for Gaussian distribution and print histograms \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "colors=  [ 'blue', 'green', 'red', 'cyan', 'magenta', 'salmon', 'lawngreen', 'dodgerblue', 'blueviolet', 'grey', 'darkorange', 'darkgoldenrod', 'lime', 'cornflowerblue', 'blueviolet', 'brown', 'gold', 'teal', 'olive' ]\n",
    "ci= 0\n",
    "pi= 0\n",
    "fig_cols= 3\n",
    "\n",
    "\n",
    "print('{:<55}\\t{:<6}\\t{:<12}\\t{:<12}\\t{:<12}\\n'.format('Name', 'Wert', 'D’Agostino K^2', 'Shapiro-Wilk', 'Anderson-Darling'))\n",
    "\n",
    "# calculate number of rows in figure\n",
    "fig_rows= len(column_checkbox_group.value) // fig_cols\n",
    "if len(column_checkbox_group.value) % fig_cols != 0:\n",
    "    fig_rows= fig_rows + 1\n",
    "fig, ax= plt.subplots(fig_rows, fig_cols, figsize= (25, fig_rows * 10))\n",
    "\n",
    "# calculate several tests of Gaussian distribution\n",
    "for column in column_checkbox_group.value:\n",
    "    # drop missing values from dataframe and convert to values array\n",
    "    col_clean= df[column].dropna().to_numpy()\n",
    "\n",
    "    # D’Agostino’s K^2 Test\n",
    "    k2, p_k2= stats.normaltest(col_clean, axis= None)\n",
    "    alpha = 0.05\n",
    "    if p_k2 > alpha:\n",
    "        k2_gauss= 'ja'\n",
    "    else:\n",
    "        k2_gauss= 'nein'\n",
    "\n",
    "    # Shapiro-Wilk Test\n",
    "    sw, p_sw= stats.shapiro(col_clean)\n",
    "    if p_sw > alpha:\n",
    "        sw_gauss= 'ja'\n",
    "    else:\n",
    "        sw_gauss= 'nein'\n",
    "\n",
    "    ad_result= stats.anderson(col_clean)\n",
    "    ad= ad_result.statistic\n",
    "    for i in range(len(ad_result.critical_values)):\n",
    "        if ad_result.significance_level[i] != 1.0:\n",
    "            continue\n",
    "        ad_sl, ad_cv = ad_result.significance_level[i], ad_result.critical_values[i]\n",
    "        if ad_result.statistic < ad_result.critical_values[i]:\n",
    "            ad_gauss= 'ja'\n",
    "        else:\n",
    "            ad_gauss= 'nein'\n",
    "\n",
    "    print('{:<55}\\t{:<6}\\t{:<10}\\t{:<10}\\t{:<10}'.format(column, 'p', '{:.5E}'.format(p_k2), '{:.5E}'.format(p_sw),  ''))\n",
    "    print('{:<55}\\t{:<6}\\t{:<12}\\t{:<12}\\t{:<12}'.format('', 'stat', '{:.5E}'.format(k2), '{:.5E}'.format(sw), '{:.5E}'.format(ad)))\n",
    "    print('{:<55}\\t{:<6}\\t{:<12}\\t{:<12}\\t{:<12}'.format('', 'Gauss', k2_gauss , sw_gauss, ad_gauss))\n",
    "\n",
    "    if fig_rows == 1:\n",
    "        ax[pi % fig_cols].hist(col_clean, 32, color= colors[ci], label= column)\n",
    "        ax[pi % fig_cols].set_title(column)\n",
    "    else:\n",
    "        ax[pi // fig_cols][pi % fig_cols].hist(col_clean, 32, color= colors[ci], label= column)\n",
    "        ax[pi // fig_cols][pi % fig_cols].set_title(column)\n",
    "\n",
    "    pi= (pi + 1)\n",
    "    ci= (ci + 1) % len(colors)\n",
    "\n",
    "print('\\nHistogramme\\n')\n",
    "fig.show()\n",
    "\n",
    "import os\n",
    "os.makedirs('plots', exist_ok= True)\n",
    "fig.savefig('plots/' + data_file_name + '_histograms.png', dpi= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af54e4b-1451-427c-b89e-bdf6151f8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "ci= 0\n",
    "pi= 0\n",
    "\n",
    "# set number of rows in figure\n",
    "fig, ax= plt.subplots(len(column_checkbox_group.value), 1, figsize= (25, fig_rows * 20))\n",
    "\n",
    "# calculate mean, max, min and std grouped by date index\n",
    "df_date_group= df.replace(0, np.NaN).groupby(column_date_group.value)\n",
    "#df_zero_clean= df\n",
    "#for column in column_checkbox_group.value:\n",
    "#    if (df_zero_clean[column] == 0).all() == False:\n",
    "#        df_zero_clean[column].replace(0, np.NaN, inplace=True)\n",
    "#df_date_group= df_zero_clean.groupby(column_date_group.value)\n",
    "\n",
    "df_date_group_mean= df_date_group.mean()\n",
    "df_date_group_std= df_date_group.std()\n",
    "df_date_group_min= df_date_group.min()\n",
    "df_date_group_max= df_date_group.max()\n",
    "\n",
    "print('\\nTrends calculated with linear regression:\\n')\n",
    "print('{:<55}\\t{:<16}\\n'.format('Name', 'Trend'))\n",
    "\n",
    "# run least squares linear regression with two different libraries to check if everything is fine\n",
    "for column in column_checkbox_group.value:\n",
    "    # drop missing values from dataframe\n",
    "    #col_clean= df[column].dropna()\n",
    "    df_date_group_mean[column].fillna(value= 0, inplace= True)\n",
    "    col_clean= df_date_group_mean[column].dropna()\n",
    "    # run regression method 1 with numpy polynomial fit with order 1\n",
    "    coeffs_polyfit= np.polyfit(range(0, len(col_clean)), col_clean, 1)\n",
    "    # create matrix from values and run regression method 2 with numpy linear leastsquares\n",
    "    a= np.vstack([range(0, len(col_clean)), np.ones(len(col_clean))]).T\n",
    "    coeffs_lstsq= np.linalg.lstsq(a, col_clean, None)[0]\n",
    "    # print to check if results of polyfit and lstsq are equal\n",
    "    #print(coeffs_polyfit, '\\n', coeffs_lstsq)\n",
    "    # print result table line\n",
    "    print('{:<55}\\t{:+.6f}'.format(column, coeffs_polyfit[0]))\n",
    "\n",
    "    # create y values to plot trend\n",
    "    yn = np.polyval(coeffs_polyfit, range(0, len(col_clean)))\n",
    "    # plot values and trend\n",
    "    if len(column_checkbox_group.value) == 1:\n",
    "        #ax.scatter(df_date_group_mean.index, df_date_group_mean[column], c= colors[ci], label= column)\n",
    "        ax.plot(df_date_group_mean.index, yn, c= colors[ci])\n",
    "        trend_patch= mpatches.Patch(color= colors[ci], label= 'Trend: ' + '{:.6f}'.format(coeffs_polyfit[0]))\n",
    "        ci= (ci + 1) % len(colors)\n",
    "        ax.errorbar(df_date_group_mean.index, df_date_group_mean[column], yerr= df_date_group_std[column], marker= 'o', c= colors[ci], linestyle= 'none', capsize= 5, elinewidth= 3, solid_capstyle= 'butt')\n",
    "        error_patch= mpatches.Patch(color= colors[ci], label= column)\n",
    "        ax.legend(handles= [ error_patch, trend_patch ], fontsize=18)\n",
    "    else:\n",
    "        #ax[pi].scatter(df_date_group_mean.index, df_date_group_mean[column], c= colors[ci], label= column)\n",
    "        ax[pi].plot(df_date_group_mean.index, yn, c= colors[ci])\n",
    "        trend_patch= mpatches.Patch(color= colors[ci], label= 'Trend: ' + '{:.6f}'.format(coeffs_polyfit[0]))\n",
    "        ci= (ci + 1) % len(colors)\n",
    "        ax[pi].errorbar(df_date_group_mean.index, df_date_group_mean[column], yerr= [ df_date_group_mean[column] - df_date_group_min[column], df_date_group_max[column] - df_date_group_mean[column] ], marker= 'o', c= colors[ci], linestyle= 'none', capsize= 5, elinewidth= 3, solid_capstyle= 'butt')\n",
    "        error_patch= mpatches.Patch(color= colors[ci], label= column)\n",
    "        ax[pi].legend(handles= [ error_patch, trend_patch ], fontsize=18)\n",
    "    pi= (pi + 1)\n",
    "    ci= (ci + 1) % len(colors)\n",
    "\n",
    "print('\\n')\n",
    "fig.show()\n",
    "fig.savefig('plots/' + data_file_name + '_trends_linear.png', dpi= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cadc6-6756-423f-ac75-db20c4d8b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# install pandas_profiling module\n",
    "!pip install pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cf5ba-33db-46ef-bdba-c57e56185275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "\n",
    "pfrep= pandas_profiling.ProfileReport(df)\n",
    "pfrep.to_file('plots/' + data_file_name + '_profile_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d62847-ea3c-462b-9fee-991e0f764dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show correlation\n",
    "\n",
    "corr= df.corr()\n",
    "corr.style.background_gradient(cmap= 'coolwarm').format(precision= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56dda34-edfd-4435-a426-e792f5f60a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# install Mann Kendall test module\n",
    "!pip install pymannkendall\n",
    "\n",
    "import pymannkendall as mk\n",
    " \n",
    "mann_kendall= pd.DataFrame(index= [ 'trend', 'h', 'p', 'z', 'Tau', 's', 'var_s', 'slope', 'intercept' ])\n",
    "\n",
    "# perform Mann-Kendall test\n",
    "for column in column_checkbox_group.value:\n",
    "    mann_kendall[column]= mk.original_test(df_date_group_mean[column].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324f5c8-d9fb-49a1-88cf-d9d2f14e90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mann_kendall.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32dd478-9699-4bd4-bbc6-59ae58f234da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTrends calculated with Mann-Kendall Test:\\n')\n",
    "\n",
    "print('{:<55}\\t{:<12}\\n'.format('Name', 'Mann-Kendall'))\n",
    "# run least squares linear regression with two different libraries to check if everything is fine\n",
    "for column in column_checkbox_group.value:\n",
    "    print('{:<55}\\t{:+.6f}'.format(column, mann_kendall[column].slope))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7b254-c9bb-41ca-8efb-ed25387da987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
